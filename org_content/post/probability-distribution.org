#+HUGO_BASE_DIR: ../../
#+HUGO_SECTION: post

#+HUGO_AUTO_SET_LASTMOD: nil

#+TITLE: Basics of Probability Distribution of Random Variable

#+DATE: 2019-05-05

#+HUGO_TAGS: "probability distribution" "random variable"
#+HUGO_CATEGORIES: "statistics" "probability"
#+AUTHOR:
#+HUGO_CUSTOM_FRONT_MATTER: :author "Peter Lo"

#+HUGO_DRAFT: true

Roughly speaking, probability describes how likely a certain event
takes places, and probability distribution refers to how likely a
random variable takes different values. In this post, we look at some
examples to get an intuitive idea of sample space, events,
probability, probability distributions, and some ways of describing a
probability distribution.

* Probability

/Probability/ is used to quantitatively describe how /likely/ an
/event/ would occur. A /probability/ is a number between (inclusive) 0
and 1, where a larger value means the event is more /likely/.

** Frequentist and Bayesian interpretation

There are two slightly different interpretations of probability:
/frequentist/ and /Bayesian/ interpretation.

#+begin_quote
Frequentist interpreation:

The probability of an event is the limiting /relative frequency/ that
the event occurs if the number of trials approaches infinity.
#+end_quote

For example, under the frequentist interpreation, if we say the
probability of coin toss giving a tail is 0.6, what is meant is that
/if/ we flip the coin a /huge/ number of times, 60% of the flips would
result in a tail.

Note that this interpretation requires that it is at least conceivable
to repeat the trial to calculate the relative frequency that the event
occurs. For example, if we were to make sens of the "probability that
the moon is made of cheese", we might need to imagine the moon gets
repeatedly created, and caclulate the proportion where the moon is
made of cheese.

On the other hand, the Bayesian interpretation of probability is more
liberal.

#+begin_quote
Bayesian interpretation:

The probability of an event is the /degree of belief/ that it occurs.
#+end_quote

Under the Bayesian interpretation, we can speak of /subjective/
probability, in addition to /objective probability, and there is no
difficulty of making sense of the "probability that the moon is made
of cheese". Also, by the /Law of large number/, the relative frequency
of an event will tend to the objective probability if the number of
trials tends to infinity.

In practice, it does not matter much which interpretation you
subscribe to, because the formulae related to probability are mostly
the same (sometimes frequentists refuse to give interpretation to some
formulae in some cases). The difference is more philosophical than
practical.

** Sample spaces and events
Whether we use frequentist or Bayesian interpretation of probability,
one key ingredient is /event/. For an event to make sense, it suffices
to have a clear criteria to determine whether an event has
occured. For example, if we throw a dice, we may consider the
following events:

- event A: the number is 2
- event B: the number is even
- event C: the number is odd
- event D: the number is less than 3
- event E: the number is both even and odd

We note that the above events are related. Since 2 is even and is less
than 3, event A implies both event B and event D. Event C and D have
some overlap (e.g. the number 1 is both odd and less than 3), but
neither one implies the other. Also, an integer is either even or odd,
but not both, so event B and event C are /exclusive/, and together
they are /exhaustive/. Moreover, event E is an impossible event.

When modeling a situation, we can formally define a /sample space/,
which could be regarded as the set of atomic events, and subsets of
the sample space are the events. Note that we may model the same
situation with different sample spaces, but some sample space may be
more intuitive than others.

*** Example: Dice throwing
For example, in the dice throwing example, we could define the sample
space as {1, 2, 3, 4, 5, 6}, then the 4 events above are respectively:

- event A: {2}
- event B: {2, 4, 6}
- event C: {1, 3, 5}
- event D: {1, 2}
- event E: {}

*** Example: Coin tossing
As another example, for tossing a coin once, we may define the sample
space as {H, T} for "Head" and "Tail". Note that the sample space can
consist of any objects, not just numbers. Also note that by defining
the sample space as {H, T}, we are implicitly excluding the
possibility that the coin may land on its edge, and therefore giving
neither a "Head" nor a "Tail".

*** Example: Multiple coin tossing
We may also model multiple coin tossing. E.g. if we model 3 coin
tossings, we may define the sample space as {(H,H,H), (H,H,T),
(H,T,H), (H,T,T), (T,H,H), (T,H,T), (T,T,H), (T,T,T)}, then we may
consider events such as:

- "two heads out of 3 tosses": {(H,H,T), (H,T,H), (T,H,H)}
- "the first two tossing give the same results": {(H,H,H), (H,H,T), (T,T,H), (T,T,T)}

We can even model infinitely many coin tossings, e.g. by defining the
sample space as $\{(x_1, x_2, ...): x_i \in \{H,T\}\}$. Then we may
consider events such as:

- "the first toss is head": $\{(H,x_2,x_3,...): x_i \in \{H,T\}\}$
- "it takes 3 tosses to get the first head": $\{(T,T,H,x_4,x_5,...): x_i \in \{H,T\}\}$
- "head and tail appears alternately": $\{(H,T,H,T,...), (T,H,T,H,...)\}$

*** Example: Time until a newly manufactured light bulb fails
For modeling time until some events occur, we may define the sample
space as $\{x: x>0\}$. For example, the time (in hours) until a newly
manufactured light bulb fails. Although we can measure "time" only up
to a certain precision, "time" is conceptually /continuous/, and
therefore often modeled as a continuous real value. We may then
consider events such as:

- "the light bulb will not fail in the first 10,000 hours": $\{x: x>10 000\}$
- "the light bulb will not last more than 100,000 hours": $\{x: x<= 100 000\}$

On the other hand, in some cases, modeling the time as integers may be
sufficient, e.g. when we want to count the number of days of a patient
staying in the hospital, but do not want to consider fractional number
of days. In such case, we may take the sample space as {0, 1, 2, ...}.

*** Example: Height and weight
For height and weight of a person, similar to time, although we can
measure height and weight only up to a certain precision, they are
conceptually continuous, and therefore often modeled as continuous
real values. We may define the sample space as $\{(h,w): h>0, w>0\}$
(suppose we measure height h in cm, and weight w in kg).

** Random variable

random variable: function from sample space to a value

probability space: sample space with probability of events

* Distribution

arbitrary distribution

discrete random varibles: probability mass function

continuous random variables: probability density function

cumulative distribution

parametric distribution: use a few parameters to summarize the distribution
